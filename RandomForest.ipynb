{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TICKET_NUMBER                  object\n",
      "TICKET_STATUS                  object\n",
      "SEVERITY                        int64\n",
      "CUST_AFFECT                     int64\n",
      "EQUIPMENT_ID                   object\n",
      "EQ_REGION                      object\n",
      "EQ_MARKET_CLUSTER              object\n",
      "EQ_MARKET                      object\n",
      "OPS_DISTRICT                   object\n",
      "OPS_ZONE                       object\n",
      "SHORT_DESCRIPTION              object\n",
      "PROBLEM_CATEGORY               object\n",
      "PROBLEM_SUBCATEGORY            object\n",
      "PROBLEM_DETAIL                 object\n",
      "ASSIGNED_TO                    object\n",
      "ASSIGNED_DEPARTMENT            object\n",
      "ASSIGNED_REGION                object\n",
      "ASSIGNED_MARKET                object\n",
      "ASSIGNED_DISTRICT_SUB_DEPT     object\n",
      "ASSIGNED_ZONE                  object\n",
      "CREATE_DATE                     int64\n",
      "REPEAT_TICKET                 float64\n",
      "RESOLUTION_CATEGORY            object\n",
      "RESOLUTION_TYPE                object\n",
      "RESOLUTION                     object\n",
      "RESOLUTION_NOTES               object\n",
      "RESOLVED_TIME                 float64\n",
      "CLOSED_TIME                   float64\n",
      "CLOB_FIELD_VALUE               object\n",
      "CLOB_FIELD_ID                   int64\n",
      "CLOB_FIELD_VALUE_1             object\n",
      "LOCATION_NAME                  object\n",
      "ADDRESS                        object\n",
      "ADDRESS2                       object\n",
      "CITY                           object\n",
      "STATE                          object\n",
      "ZIP_CODE                       object\n",
      "LAT_LONG_TYPE                 float64\n",
      "LATITUDE                       object\n",
      "LATITUDE_DECIMAL              float64\n",
      "LAT_DEG                       float64\n",
      "LAT_MIN                       float64\n",
      "LAT_SEC                       float64\n",
      "LAT_DIR                       float64\n",
      "LONGITUDE                      object\n",
      "LONGITUDE_DECIMAL             float64\n",
      "LONG_DEG                      float64\n",
      "LONG_MIN                      float64\n",
      "LONG_SEC                      float64\n",
      "LONG_DIR                      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sets import Set\n",
    "data = pd.read_csv('HighLevelTicketLocationData_1.csv')\n",
    "\n",
    "print data.dtypes\n",
    "\n",
    "# Simple program that demonstrates how to invoke Azure ML Text Analytics API: key phrases, language and sentiment detection.\n",
    "import urllib2\n",
    "import urllib\n",
    "import sys\n",
    "import base64\n",
    "import json\n",
    "\n",
    "category_counter = {}\n",
    "\n",
    "\n",
    "\n",
    "# Azure portal URL.\n",
    "base_url = 'https://westus.api.cognitive.microsoft.com/'\n",
    "# Your account key goes here.\n",
    "account_key = '**YOUR_KEY_HERE**'\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Ocp-Apim-Subscription-Key':account_key}\n",
    "\n",
    "#input_texts = '{\"documents\":[{\"id\":\"1\",\"text\":\"MWR993040\"},{\"id\":\"2\",\"text\":\"NodeB/ BTS Restart Request\"},{\"id\":\"3\",\"text\":\"DVL00257 5 CORRELATED: NO CONTACT TO BOARDAlarm Monitored Attribute= rrh 141-0-0  Number Of Filtered Alarms Since Last Reporting= 0Last Filtering Time= 1970/01/01 00:00:00  (NE Time) Last Filtering Time=1969/12/31 19:00:00 000 (GMT -5:00)  Last Filtering \"},{\"id\":\"4\",\"text\":\"PRVDRIURC01 Centest comm down, Ping, No Answer.  Check CENTEST connections and connectors. Call MOBILITY at 866-299-6216 Opt 2 for test assist. Need laptop computer with terminal program and interface cable when you call MOBILITY. Do Not Power Cycle\"},{\"id\":\"5\",\"text\":\"Run and connect external alarms to PNC cabinet and LTE DUS\"},{\"id\":\"6\",\"text\":\"MWR993049\"},{\"id\":\"7\",\"text\":\"CRTNTX35CR9S01/DLLSDXM15205 5 UMTS ALU Small Cell CS Retainability Alert NA - UMTS ALU Small Cell CS Retainability Alert - SCORE 90.00 - FAILURES 3 - RRC_Rej_MaxUsers 0 - UC UC3 - ACCESS MODE openAccess - DATE: 20160211 HOUR: 1600\"},{\"id\":\"8\",\"text\":\"NWL05576 4 RBS DC MNAlarm Monitored Attribute= dbu 1-1-0  Number Of Filtered Alarms Since Last Reporting= 0Last Filtering Time= 1970/01/01 00:00:00  (NE Time) Last Filtering Time=1969/12/31 19:00:00 000 (GMT -5:00)  Last Filtering Type= none dbu 1-1-0\"},{\"id\":\"9\",\"text\":\"MNCHMOAQCRAR11/MOU2859 5 CORRELATED: Communication Subsystem Failure(306) FaultCode=OAM_0150_00100 AlarmID=5162552500666 : Loss of supervision\"}]}'\n",
    "\n",
    "\n",
    "num_detect_langs = 1;\n",
    "\n",
    "# Detect key phrases.\n",
    "def get_keywords(input_text_short_descriptions):\n",
    "    batch_keyphrase_url = base_url + 'text/analytics/v2.0/keyPhrases'\n",
    "    req = urllib2.Request(batch_keyphrase_url, input_text_short_descriptions, headers) \n",
    "\n",
    "    response = urllib2.urlopen(req)\n",
    "    result = response.read()\n",
    "    obj = json.loads(result)\n",
    "    return obj\n",
    "#print get_keywords(input_text_short_descriptions)\n",
    "\n",
    "categories = data['RESOLUTION_CATEGORY']\n",
    "types = data['RESOLUTION_TYPE']\n",
    "\n",
    "for i in xrange(len(categories)):\n",
    "    category = categories[i]\n",
    "    t = types[i]\n",
    "    if category in category_counter:\n",
    "        category_counter[category].add(t)\n",
    "    else:\n",
    "        category_counter[category] = set([t])\n",
    "\n",
    "del category_counter[np.nan]\n",
    "\n",
    "#print len(category_counter)\n",
    "\n",
    "#print category_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in ['TICKET_NUMBER','EQUIPMENT_ID', 'EQ_REGION', 'EQ_MARKET_CLUSTER', 'EQ_MARKET','LATITUDE','LONGITUDE']:\n",
    "    del data[column]\n",
    "\n",
    "#data.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transforming TICKET_STATUS to int\n",
      "\n",
      "Transforming OPS_DISTRICT to int\n",
      "\n",
      "Transforming OPS_ZONE to int\n",
      "\n",
      "Transforming PROBLEM_CATEGORY to int\n",
      "\n",
      "Transforming PROBLEM_SUBCATEGORY to int\n",
      "\n",
      "Transforming PROBLEM_DETAIL to int\n",
      "\n",
      "Transforming ASSIGNED_TO to int\n",
      "\n",
      "Transforming ASSIGNED_DEPARTMENT to int\n",
      "\n",
      "Transforming ASSIGNED_REGION to int\n",
      "\n",
      "Transforming ASSIGNED_MARKET to int\n",
      "\n",
      "Transforming ASSIGNED_DISTRICT_SUB_DEPT to int\n",
      "\n",
      "Transforming ASSIGNED_ZONE to int\n",
      "\n",
      "Transforming RESOLUTION_TYPE to int\n",
      "\n",
      "Transforming RESOLUTION to int\n",
      "\n",
      "Transforming"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanmanojthakkar/anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:275: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  return aux[:-1][aux[1:] == aux[:-1]]\n",
      "/Users/rohanmanojthakkar/anaconda/lib/python2.7/site-packages/numpy/lib/arraysetops.py:216: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RESOLUTION_NOTES to int\n",
      "\n",
      "Transforming LOCATION_NAME to int\n",
      "\n",
      "Transforming ADDRESS to int\n",
      "\n",
      "Transforming ADDRESS2 to int\n",
      "\n",
      "Transforming CITY to int\n",
      "\n",
      "Transforming STATE to int\n",
      "\n",
      "Transforming ZIP_CODE to int\n",
      "TICKET_STATUS                   int64\n",
      "SEVERITY                        int64\n",
      "CUST_AFFECT                     int64\n",
      "OPS_DISTRICT                    int64\n",
      "OPS_ZONE                        int64\n",
      "SHORT_DESCRIPTION              object\n",
      "PROBLEM_CATEGORY                int64\n",
      "PROBLEM_SUBCATEGORY             int64\n",
      "PROBLEM_DETAIL                  int64\n",
      "ASSIGNED_TO                     int64\n",
      "ASSIGNED_DEPARTMENT             int64\n",
      "ASSIGNED_REGION                 int64\n",
      "ASSIGNED_MARKET                 int64\n",
      "ASSIGNED_DISTRICT_SUB_DEPT      int64\n",
      "ASSIGNED_ZONE                   int64\n",
      "CREATE_DATE                     int64\n",
      "REPEAT_TICKET                 float64\n",
      "RESOLUTION_CATEGORY            object\n",
      "RESOLUTION_TYPE                 int64\n",
      "RESOLUTION                      int64\n",
      "RESOLUTION_NOTES                int64\n",
      "RESOLVED_TIME                 float64\n",
      "CLOSED_TIME                   float64\n",
      "CLOB_FIELD_VALUE               object\n",
      "CLOB_FIELD_ID                   int64\n",
      "CLOB_FIELD_VALUE_1             object\n",
      "LOCATION_NAME                   int64\n",
      "ADDRESS                         int64\n",
      "ADDRESS2                        int64\n",
      "CITY                            int64\n",
      "STATE                           int64\n",
      "ZIP_CODE                        int64\n",
      "LAT_LONG_TYPE                 float64\n",
      "LATITUDE_DECIMAL              float64\n",
      "LAT_DEG                       float64\n",
      "LAT_MIN                       float64\n",
      "LAT_SEC                       float64\n",
      "LAT_DIR                       float64\n",
      "LONGITUDE_DECIMAL             float64\n",
      "LONG_DEG                      float64\n",
      "LONG_MIN                      float64\n",
      "LONG_SEC                      float64\n",
      "LONG_DIR                      float64\n",
      "dtype: object\n",
      "(7467, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'O' and column not in ['RESOLUTION_CATEGORY','SHORT_DESCRIPTION','CLOB_FIELD_VALUE','CLOB_FIELD_VALUE_1']:\n",
    "        print \n",
    "        print 'Transforming',column,'to int'\n",
    "        #print data[column][0]\n",
    "        #print 'yo'\n",
    "        le.fit(data[column])\n",
    "        l = le.transform(data[column])\n",
    "        data[column] = l\n",
    "print data.dtypes\n",
    "\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CREATE_DATE', 'OPS_DISTRICT', 'RESOLUTION_NOTES', 'RESOLUTION_TYPE', 'CUST_AFFECT', 'ASSIGNED_MARKET', 'PROBLEM_SUBCATEGORY', 'OPS_ZONE', 'PROBLEM_CATEGORY', 'LOCATION_NAME', 'TICKET_STATUS', 'CLOB_FIELD_VALUE', 'ASSIGNED_TO', 'SHORT_DESCRIPTION', 'ZIP_CODE', 'RESOLUTION', 'ASSIGNED_DEPARTMENT', 'ASSIGNED_REGION', 'STATE', 'LATITUDE_DECIMAL', 'LONGITUDE_DECIMAL', 'ASSIGNED_ZONE', 'CITY', 'ASSIGNED_DISTRICT_SUB_DEPT', 'SEVERITY', 'ADDRESS2', 'CLOB_FIELD_ID', 'PROBLEM_DETAIL', 'CLOB_FIELD_VALUE_1', 'ADDRESS']\n",
      "['CREATE_DATE', 'OPS_DISTRICT', 'RESOLUTION_NOTES', 'RESOLUTION_TYPE', 'CUST_AFFECT', 'ASSIGNED_MARKET', 'PROBLEM_SUBCATEGORY', 'OPS_ZONE', 'PROBLEM_CATEGORY', 'LOCATION_NAME', 'TICKET_STATUS', 'ASSIGNED_TO', 'ZIP_CODE', 'RESOLUTION', 'ASSIGNED_DEPARTMENT', 'ASSIGNED_REGION', 'STATE', 'LATITUDE_DECIMAL', 'LONGITUDE_DECIMAL', 'ASSIGNED_ZONE', 'CITY', 'ASSIGNED_DISTRICT_SUB_DEPT', 'SEVERITY', 'ADDRESS2', 'CLOB_FIELD_ID', 'PROBLEM_DETAIL', 'ADDRESS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CREATE_DATE                     int64\n",
       "OPS_DISTRICT                    int64\n",
       "RESOLUTION_NOTES                int64\n",
       "RESOLUTION_TYPE                 int64\n",
       "CUST_AFFECT                     int64\n",
       "ASSIGNED_MARKET                 int64\n",
       "PROBLEM_SUBCATEGORY             int64\n",
       "OPS_ZONE                        int64\n",
       "PROBLEM_CATEGORY                int64\n",
       "LOCATION_NAME                   int64\n",
       "TICKET_STATUS                   int64\n",
       "ASSIGNED_TO                     int64\n",
       "ZIP_CODE                        int64\n",
       "RESOLUTION                      int64\n",
       "ASSIGNED_DEPARTMENT             int64\n",
       "ASSIGNED_REGION                 int64\n",
       "STATE                           int64\n",
       "LATITUDE_DECIMAL              float64\n",
       "LONGITUDE_DECIMAL             float64\n",
       "ASSIGNED_ZONE                   int64\n",
       "CITY                            int64\n",
       "ASSIGNED_DISTRICT_SUB_DEPT      int64\n",
       "SEVERITY                        int64\n",
       "ADDRESS2                        int64\n",
       "CLOB_FIELD_ID                   int64\n",
       "PROBLEM_DETAIL                  int64\n",
       "ADDRESS                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "l = dict(pd.isnull(data).any())\n",
    "\n",
    "c = l.copy()\n",
    "\n",
    "for col in l:\n",
    "    if l[col]:\n",
    "        del c[col]\n",
    "features = c.keys()\n",
    "\n",
    "print features\n",
    "\n",
    "#features = list(data.columns)\n",
    "\n",
    "# Since this is the output\n",
    "#features.remove('RESOLUTION_CATEGORY')\n",
    "\n",
    "\n",
    "\n",
    "# Temporarily removing. Find a fix for this later - use Cognitive API with RF maybe?\n",
    "features.remove('SHORT_DESCRIPTION')\n",
    "features.remove('CLOB_FIELD_VALUE')\n",
    "features.remove('CLOB_FIELD_VALUE_1')\n",
    "#features.remove('CLOB_FIELD_ID')\n",
    "print features\n",
    "data[features].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7467\n",
      "5076\n",
      "65\n",
      "65\n",
      "65\n",
      "65\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "206\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "213\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "283\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "from sets import Set\n",
    "# Temporarily removing. Find a fix for this later - use Cognitive API with RF maybe?\n",
    "short_descriptions = data['SHORT_DESCRIPTION']\n",
    "print len(short_descriptions)\n",
    "print len(set(short_descriptions))\n",
    "#data['CLOB_FIELD_VALUE']\n",
    "#data['CLOB_FIELD_VALUE_1']\n",
    "\n",
    "input_text_short_descriptions = '{\"documents\":['\n",
    "\n",
    "temp = '{\"documents\":['\n",
    "\n",
    "unique_short_descriptions = list(set(short_descriptions))\n",
    "# since some descriptions are repeating, need not incur unncessary transactions\n",
    "\n",
    "#len(unique_short_descriptions)\n",
    "import shelve\n",
    "\n",
    "description_to_keywords = shelve.open('description_to_keywords.db')\n",
    "\n",
    "for count in range(len(short_descriptions)):\n",
    "    print len(description_to_keywords)\n",
    "    short_description = unique_short_descriptions[count]\n",
    "    if short_description not in description_to_keywords:\n",
    "        #input_text_short_descriptions += '{\"id\":\"'+str(count)+'\",\"text\":\"'+short_description+'\"},'\n",
    "        temp += '{\"id\":\"'+str(count)+'\",\"text\":\"'+short_description+'\"}]}'\n",
    "        try:\n",
    "            description_to_keywords[short_description] = get_keywords(temp)['documents'][0]['keyPhrases']\n",
    "        except urllib2.HTTPError as err:\n",
    "            if err.code == 400:\n",
    "                print 'Error on',count\n",
    "                pass\n",
    "\n",
    "print len(description_to_keywords)\n",
    "#input_text_short_descriptions = input_text_short_descriptions[:-1]\n",
    "#input_text_short_descriptions += ']}'\n",
    "#print input_text_short_descriptions\n",
    "#print get_keywords(temp)['documents'][0]['keyPhrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for keyphrase_analysis in obj['documents']:\n",
    "    description_to_keywords[unique_short_descriptions[int(keyphrase_analysis['id'])]] = map(str,keyphrase_analysis['keyPhrases'])\n",
    "    print('Key phrases ' + str(keyphrase_analysis['id']) + ': ' + ', '.join(map(str,keyphrase_analysis['keyPhrases'])))\n",
    "\n",
    "#description_to_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "given = data[pd.notnull(data['RESOLUTION_CATEGORY'])].copy()\n",
    "unknown = data[pd.isnull(data['RESOLUTION_CATEGORY'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print given.shape\n",
    "given[features].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print unknown.shape\n",
    "unknown[features].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "y_given,_ = pd.factorize(train['RESOLUTION_CATEGORY'])\n",
    "print y_given#,_\n",
    "\"\"\"\n",
    "category_mapping = {}\n",
    "counter = 0\n",
    "for resolution_category in given['RESOLUTION_CATEGORY']:\n",
    "    if resolution_category not in category_mapping:\n",
    "        category_mapping[resolution_category] = counter\n",
    "        counter += 1\n",
    "print category_mapping\n",
    "\n",
    "def get_factor(category):\n",
    "    return category_mapping[category]\n",
    "\n",
    "reverse_mapping = {}\n",
    "\n",
    "for category in category_mapping:\n",
    "    factor = category_mapping[category]\n",
    "    reverse_mapping[factor] = category\n",
    "\n",
    "print reverse_mapping\n",
    "\n",
    "def get_category(factor):\n",
    "    return reverse_mapping[factor]\n",
    "    \n",
    "y_given = [get_factor(category) for category in given['RESOLUTION_CATEGORY']]\n",
    "print len(y_given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "d = {}\n",
    "\n",
    "for x in train['RESOLUTION_CATEGORY']:\n",
    "    if x in d:\n",
    "        d[x] += 1\n",
    "    else:\n",
    "        d[x] = 1\n",
    "print d\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a random forest classifier. By convention, clf means 'classifier'\n",
    "clf = RandomForestClassifier(n_jobs=-1,n_estimators=100)\n",
    "\n",
    "# Train the classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(given[features], y_given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualizatiins of RF models\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "#dotfile = six.StringIO()\n",
    "i_tree = 0\n",
    "for tree_in_forest in clf.estimators_:\n",
    "    with open('tree_' + str(i_tree) + '.png', 'w') as my_file:\n",
    "        my_file = tree.export_graphviz(tree_in_forest, out_file = my_file)\n",
    "    i_tree = i_tree + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import os\n",
    "os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a random forest classifier. By convention, clf means 'classifier'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, output_train, output_test = train_test_split(given[features], y_given, test_size=0.2, random_state=42)\n",
    "# Train the classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(X_train, output_train)\n",
    "\n",
    "predictions_new = clf.predict(X_test)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for p in xrange(len(predictions_new)):\n",
    "    #print predictions_new[p],output_test[p]\n",
    "    if predictions_new[p] == output_test[p]:\n",
    "        count += 1\n",
    "    \"\"\"    \n",
    "        print 'Hit'\n",
    "    else:\n",
    "        print 'Miss'\n",
    "    \"\"\"    \n",
    "print 100.0*count/len(predictions_new),'% accuracy observed in 80-20 split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-fold cross calidation\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def measure_score(model,x,y):\n",
    "    return model.score(x,y)\n",
    "\n",
    "score = sklearn.cross_validation.cross_val_score(clf, given[features],y_given, cv=10, scoring=measure_score).mean()\n",
    "\n",
    "print 100.0*score,'% accuracy observed in 10-fold cross validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(unknown[features])\n",
    "#print predictions\n",
    "\n",
    "unknown['RESOLUTION_CATEGORY'] = [get_category(prediction) for prediction in predictions]\n",
    "unknown['RESOLUTION_CATEGORY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown.to_csv('output_of_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
